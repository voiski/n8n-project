# N8n minimal server - for local
# Source from:
# * https://docs.n8n.io/hosting/installation/server-setups/docker-compose/#5-create-local-files-directory
services:
  pgvector:
    image: pgvector/pgvector:pg17
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: "n8n-pgvector"
      POSTGRES_USER: "n8n"
      POSTGRES_DB: "db"
    volumes:
      - pgvector_data:/var/lib/postgresql/data

  n8n:
    image: docker.n8n.io/n8nio/n8n
    restart: always
    depends_on:
      - ollama
    ports:
      - "5678:5678"
    environment:
      # https://docs.n8n.io/hosting/configuration/environment-variables/deployment/
      - N8N_EDITOR_BASE_URL=http://localhost:5678
      - NODE_ENV=local
      - GENERIC_TIMEZONE=${GENERIC_TIMEZONE:-America/Sao_Paulo}
    volumes:
      - n8n_data:/home/node/.n8n
      - ./local-files:/files

  ollama:
    image: ollama/ollama
    restart: unless-stopped
    ports:
      - 11434:11434
    labels:
      - traefik.enable=true
    environment:
      - OLLAMA_NUM_PARALLEL=4
      - OLLAMA_MAX_LOADED_MODELS=3
    volumes:
      - ollama_data:/root/.ollama
      # https://collabnix.com/setting-up-ollama-models-with-docker-compose-a-step-by-step-guide/
      # - ./modelfiles:/modelfiles

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    restart: unless-stopped
    depends_on:
      - ollama
    ports:
      - 3000:8080
    environment:
      # https://docs.openwebui.com/getting-started/env-configuration#default_models
      - ENABLE_OPENAI_API=false
      - OLLAMA_BASE_URLS=http://ollama:11434
      - ENV=dev
      - WEBUI_AUTH=False
      - WEBUI_NAME=valiantlynx AI
      - WEBUI_URL=http://localhost:8080
      - WEBUI_SECRET_KEY=t0p-s3cr3t

volumes:
  n8n_data:
  ollama_data:
  pgvector_data:
